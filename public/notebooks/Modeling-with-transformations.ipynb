{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddd1c06-7458-4fd8-9d14-2c27b4f1a222",
   "metadata": {},
   "source": [
    "# Modeling With Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb7c583-2dde-4a65-a3e7-1e7b4ec0d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c2843-a7ba-4137-9edd-1d5757fbfc66",
   "metadata": {},
   "source": [
    "## Import Some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e78984-a5af-4ea5-b08d-79a6e1ae1537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataUrl = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\n",
    "dataFromWeb = pd.read_csv(dataUrl)\n",
    "dataFromWeb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016a6922-f68e-4b92-a862-359fa89495a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelField = 'charges'\n",
    "featureData = dataFromWeb.drop(labelField, axis=1)\n",
    "labelData = dataFromWeb[labelField]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994b61a-c8f1-48ae-9b55-ad9a434d71ef",
   "metadata": {},
   "source": [
    "## Split into Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61547f4-ff75-4ccb-99b7-5ad0cd8c0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataPercentage = .2 # how much of our data should we use for \"testing\"\n",
    "randomVal = 42\n",
    "feature_training_data, feature_testing_data, label_training_data, label_testing_data = train_test_split(featureData, \n",
    "                                                    labelData, \n",
    "                                                    test_size=testDataPercentage, \n",
    "                                                    random_state=randomVal) # set random state for reproducible splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe3888-741b-4b96-9fa7-1e6b1c1f611c",
   "metadata": {},
   "source": [
    "## Transform\n",
    "The `make_column_transformer` ([docs](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html)) function can take a list of transformer functions along with a list of columns to apply the transformer to. This creates a transformer instance.  \n",
    "The transformer instance, then, gets fitted to the data with the `fit` method.  \n",
    "The transformer instnace, then, gets used with the data with the `transform` method.  \n",
    "Here will be applied two transformers:\n",
    "- the `MinMaxScaler`([docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)), to scale the `age`, `bmi`, and `children` column values to values between 0-and-1\n",
    "- the `OneHotEncoder`([docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)), to ohe the `sex`, `smoker`, and `region` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d67225b-7f56-4f1e-9225-45fac99a2dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;minmaxscaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;minmaxscaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">minmaxscaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'smoker', 'region'])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTransformer = make_column_transformer(\n",
    "    # get all values between 0 and 1\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "dataTransformer.fit(feature_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a4d2d-16d2-4aed-8e2d-1388843edbe2",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6719456-8d61-4b32-b0f7-83e3c2f7649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normailized_feature_training_data = dataTransformer.transform(feature_training_data)\n",
    "normailized_feature_testing_data = dataTransformer.transform(feature_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f848d59-b552-49ad-abad-791b7c8cda5c",
   "metadata": {},
   "source": [
    "### Compare normalized vs non-normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ea9d2b-c117-48b3-bb4d-ead9497714e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normailized_feature_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51dc4bd1-9100-4f08-a246-3d4663dcb12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_training_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c20c01-daa1-4a19-98ab-784df84fede2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normailized_feature_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543db512-3552-4634-81f7-b816f150fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc2e5b-b6d8-4612-b63f-1ff6b4fbe304",
   "metadata": {},
   "source": [
    "## Build A Model\n",
    "This will be based on the `insurance_model_2` model that can be found in the `modeling-and-wrangling` notebook.  \n",
    "This model version, though, will use normalized data: one-hot-encoded column values and scaled column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa039b1-ddbf-414e-a4e0-2ed7d7aa6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "m = tf.keras.Sequential()\n",
    "epochs = 100\n",
    "# different & more layers\n",
    "l1 = tf.keras.layers.Dense(100)\n",
    "l2 = tf.keras.layers.Dense(10)\n",
    "l3 = tf.keras.layers.Dense(1)\n",
    "\n",
    "m.add(l1)\n",
    "m.add(l2)\n",
    "m.add(l3)\n",
    "\n",
    "# Compile the model\n",
    "m.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model and save the history (we can plot this)\n",
    "m_history = m.fit(normailized_feature_training_data, label_training_data, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84f7ae-933d-419b-b160-718bab127db8",
   "metadata": {},
   "source": [
    "### Review The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d90550c-378d-42fb-8312-d08dd4e54042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2221 (8.68 KB)\n",
      "Trainable params: 2221 (8.68 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a82028-24c3-4fee-8bcc-c9ba9e68fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 3437.7786 - mae: 3437.7786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3437.778564453125, 3437.778564453125]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(normailized_feature_testing_data,label_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce38430a-6367-4baa-bed2-858f8f3a830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Median: 9575.4421\n",
      "Training Label Mean: 13346.089736364485\n",
      "m MAE: 3437.778564453125\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Label Median: {label_training_data.median()}')\n",
    "print(f'Training Label Mean: {label_training_data.mean()}')\n",
    "print(f'm MAE: {m.get_metrics_result()[\"mae\"].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6503ebf-2f8f-41b4-9297-1b07975d59f1",
   "metadata": {},
   "source": [
    "Compare this model mae to the `insurance_model_2` (_im2_) model in `modeling-and-wrangling`:\n",
    "- `im2` had an MAE of `~4700`\n",
    "- the new model mae looks to be `~3400`\n",
    "\n",
    "**Normalizing this model's data, with one-hot-encoding and scaling, made this model perform better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0d081-6833-4018-b5de-b619c96959f9",
   "metadata": {},
   "source": [
    "## Experiment With The Model\n",
    "### Double The Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "660d8c21-bac6-4d46-9ad9-2b48b6df398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = tf.keras.Sequential()\n",
    "m2epochs = 200\n",
    "\n",
    "m2.add(l1)\n",
    "m2.add(l2)\n",
    "m2.add(l3)\n",
    "\n",
    "# Compile the model\n",
    "m2.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model and save the history (we can plot this)\n",
    "m2_history = m2.fit(normailized_feature_training_data, label_training_data, epochs=m2epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402202c-d75b-4737-9bdc-f56e9758f491",
   "metadata": {},
   "source": [
    "#### Review The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d964c80c-602b-44e6-aa06-d49edb3bbd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2221 (8.68 KB)\n",
      "Trainable params: 2221 (8.68 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d3b471-70ac-42f6-8e69-baae5c7d06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 3163.1138 - mae: 3163.1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3163.11376953125, 3163.11376953125]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.evaluate(normailized_feature_testing_data,label_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb1688a-f32f-4dfd-b6ec-9eac1d09cd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Median: 9575.4421\n",
      "Training Label Mean: 13346.089736364485\n",
      "m2 MAE: 3163.11376953125\n",
      "SHAPE: (1070, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Label Median: {label_training_data.median()}')\n",
    "print(f'Training Label Mean: {label_training_data.mean()}')\n",
    "print(f'm2 MAE: {m2.get_metrics_result()[\"mae\"].numpy()}')\n",
    "print(f'SHAPE: {normailized_feature_training_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7b69-0fa7-4e16-a08a-087b03f24d86",
   "metadata": {},
   "source": [
    "Increasing the Epochs _?slightly?_ made a positive impact on reducing the `mae`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18194caa-0151-42b0-800a-7d3bf6e479d0",
   "metadata": {},
   "source": [
    "### Add A Layer, Change Layer Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b215ee-84ca-4773-9b89-d1a441f10e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 3s 6ms/step - loss: 4890.2881 - mae: 4890.2881\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3555.6372 - mae: 3555.6372\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3499.9043 - mae: 3499.9043\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.0237 - mae: 3509.0237\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3540.9521 - mae: 3540.9521\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3517.5859 - mae: 3517.5859\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3518.6990 - mae: 3518.6990\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3529.7898 - mae: 3529.7898\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3534.4360 - mae: 3534.4360\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3517.0488 - mae: 3517.0488\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3534.7744 - mae: 3534.7744\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3515.1853 - mae: 3515.1853\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3517.1453 - mae: 3517.1453\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3548.9805 - mae: 3548.9805\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3507.3364 - mae: 3507.3364\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3510.1047 - mae: 3510.1047\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3598.8850 - mae: 3598.8850\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3552.2483 - mae: 3552.2483\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3627.5190 - mae: 3627.5190\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3531.2268 - mae: 3531.2268\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3530.7893 - mae: 3530.7893\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3543.9106 - mae: 3543.9106\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3573.3271 - mae: 3573.3271\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3520.0950 - mae: 3520.0950\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3768.9158 - mae: 3768.9158\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3520.4199 - mae: 3520.4199\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3560.7256 - mae: 3560.7256\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3574.5161 - mae: 3574.5161\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3610.9089 - mae: 3610.9089\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3544.8354 - mae: 3544.8354\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3526.4475 - mae: 3526.4475\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3547.3059 - mae: 3547.3059\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3592.1633 - mae: 3592.1633\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3529.9126 - mae: 3529.9126\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3548.4045 - mae: 3548.4045\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3559.6292 - mae: 3559.6292\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3513.7598 - mae: 3513.7598\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3539.0298 - mae: 3539.0298\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3504.5908 - mae: 3504.5908\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3596.6885 - mae: 3596.6885\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3572.3718 - mae: 3572.3718\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3570.4832 - mae: 3570.4832\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3524.2869 - mae: 3524.2869\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3523.8442 - mae: 3523.8442\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3520.4556 - mae: 3520.4556\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.3997 - mae: 3502.3997\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3489.3721 - mae: 3489.3721\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3560.3491 - mae: 3560.3491\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3529.6572 - mae: 3529.6572\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3504.9089 - mae: 3504.9089\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3508.7881 - mae: 3508.7881\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3510.9788 - mae: 3510.9788\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3506.0710 - mae: 3506.0710\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3558.2712 - mae: 3558.2712\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3550.1829 - mae: 3550.1829\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3530.3340 - mae: 3530.3340\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3504.7085 - mae: 3504.7085\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3507.2275 - mae: 3507.2275\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3523.6357 - mae: 3523.6357\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3542.3811 - mae: 3542.3811\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3522.3496 - mae: 3522.3496\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3597.2749 - mae: 3597.2749\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3519.0295 - mae: 3519.0295\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 3507.2795 - mae: 3507.2795\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3503.3479 - mae: 3503.3479\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3531.8118 - mae: 3531.8118\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3602.3335 - mae: 3602.3335\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3544.2197 - mae: 3544.2197\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3512.3792 - mae: 3512.3792\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3543.5198 - mae: 3543.5198\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3592.4429 - mae: 3592.4429\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3539.2012 - mae: 3539.2012\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3582.9817 - mae: 3582.9817\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3537.9119 - mae: 3537.9119\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3492.1646 - mae: 3492.1646\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3582.4971 - mae: 3582.4971\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3521.8716 - mae: 3521.8716\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3556.5381 - mae: 3556.5381\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3628.1189 - mae: 3628.1189\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3536.9333 - mae: 3536.9333\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3547.2783 - mae: 3547.2783\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.4644 - mae: 3498.4644\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3546.2336 - mae: 3546.2336\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3539.2549 - mae: 3539.2549\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.8635 - mae: 3492.8635\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3504.1799 - mae: 3504.1799\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3537.9661 - mae: 3537.9661\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3493.2207 - mae: 3493.2207\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3517.7673 - mae: 3517.7673\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3564.2373 - mae: 3564.2373\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3527.2092 - mae: 3527.2092\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3654.0620 - mae: 3654.0620\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3513.1797 - mae: 3513.1797\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3539.7449 - mae: 3539.7449\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.5242 - mae: 3509.5242\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3513.6448 - mae: 3513.6448\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3598.5984 - mae: 3598.5984\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3522.8945 - mae: 3522.8945\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3568.2788 - mae: 3568.2788\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.8835 - mae: 3498.8835\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3520.1028 - mae: 3520.1028\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.0598 - mae: 3509.0598\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3533.2000 - mae: 3533.2000\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.3853 - mae: 3509.3853\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3530.0103 - mae: 3530.0103\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3504.2649 - mae: 3504.2649\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3516.0950 - mae: 3516.0950\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3521.8760 - mae: 3521.8760\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3535.5125 - mae: 3535.5125\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3594.5701 - mae: 3594.5701\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3545.5576 - mae: 3545.5576\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3526.7427 - mae: 3526.7427\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3574.1438 - mae: 3574.1438\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3572.7832 - mae: 3572.7832\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3625.1106 - mae: 3625.1106\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3558.2129 - mae: 3558.2129\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3536.2510 - mae: 3536.2510\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3489.8787 - mae: 3489.8787\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3508.3364 - mae: 3508.3364\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.6387 - mae: 3509.6387\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3516.1399 - mae: 3516.1399\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3513.2319 - mae: 3513.2319\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3526.8970 - mae: 3526.8970\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3518.3542 - mae: 3518.3542\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3586.0806 - mae: 3586.0806\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3556.5435 - mae: 3556.5435\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3499.9497 - mae: 3499.9497\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3534.5830 - mae: 3534.5830\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3549.4773 - mae: 3549.4773\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3559.7786 - mae: 3559.7786\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3502.9041 - mae: 3502.9041\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3525.9985 - mae: 3525.9985\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3545.4492 - mae: 3545.4492\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3512.9663 - mae: 3512.9663\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3557.0881 - mae: 3557.0881\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3496.7576 - mae: 3496.7576\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3507.7644 - mae: 3507.7644\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3580.8159 - mae: 3580.8159\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3521.2104 - mae: 3521.2104\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3555.9934 - mae: 3555.9934\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3571.3367 - mae: 3571.3367\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3546.5601 - mae: 3546.5601\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3542.0952 - mae: 3542.0952\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3515.2068 - mae: 3515.2068\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3483.7578 - mae: 3483.7578\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3523.3525 - mae: 3523.3525\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3565.4807 - mae: 3565.4807\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3645.0767 - mae: 3645.0767\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3503.2488 - mae: 3503.2488\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3489.9109 - mae: 3489.9109\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3504.5786 - mae: 3504.5786\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3544.1118 - mae: 3544.1118\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3532.0950 - mae: 3532.0950\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3534.7517 - mae: 3534.7517\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3505.0679 - mae: 3505.0679\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3506.8848 - mae: 3506.8848\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3556.0361 - mae: 3556.0361\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3528.0815 - mae: 3528.0815\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3506.0342 - mae: 3506.0342\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3569.9309 - mae: 3569.9309\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3543.8269 - mae: 3543.8269\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3515.2939 - mae: 3515.2939\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 3526.0183 - mae: 3526.0183\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3546.1233 - mae: 3546.1233\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3483.1257 - mae: 3483.1257\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3519.6001 - mae: 3519.6001\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3513.6055 - mae: 3513.6055\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.6233 - mae: 3502.6233\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3539.0449 - mae: 3539.0449\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3514.3677 - mae: 3514.3677\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3569.6436 - mae: 3569.6436\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3523.1667 - mae: 3523.1667\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3531.2893 - mae: 3531.2893\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3511.9719 - mae: 3511.9719\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3519.1428 - mae: 3519.1428\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3595.8640 - mae: 3595.8640\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3543.6013 - mae: 3543.6013\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3552.3430 - mae: 3552.3430\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3594.3445 - mae: 3594.3445\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.3184 - mae: 3498.3184\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3500.4946 - mae: 3500.4946\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.3877 - mae: 3502.3877\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.7546 - mae: 3492.7546\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3572.3604 - mae: 3572.3604\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3506.9207 - mae: 3506.9207\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3601.9490 - mae: 3601.9490\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3510.8787 - mae: 3510.8787\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3585.2195 - mae: 3585.2195\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3544.9565 - mae: 3544.9565\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3519.8762 - mae: 3519.8762\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3630.3032 - mae: 3630.3032\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3554.2234 - mae: 3554.2234\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3564.4136 - mae: 3564.4136\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3517.9006 - mae: 3517.9006\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.4407 - mae: 3496.4407\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.6802 - mae: 3502.6802\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3607.3052 - mae: 3607.3052\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3607.6257 - mae: 3607.6257\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3512.8425 - mae: 3512.8425\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3495.7375 - mae: 3495.7375\n"
     ]
    }
   ],
   "source": [
    "m3 = tf.keras.Sequential()\n",
    "\n",
    "l4 = tf.keras.layers.Dense(100)\n",
    "\n",
    "m3.add(l1)\n",
    "m3.add(l4)\n",
    "m3.add(l2)\n",
    "m3.add(l3)\n",
    "\n",
    "# Compile the model\n",
    "m3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model and save the history (we can plot this)\n",
    "# , verbose=0\n",
    "m3_history = m3.fit(normailized_feature_training_data, label_training_data, epochs=m2epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cd295-f2ad-401f-9ef8-b47c985cd13a",
   "metadata": {},
   "source": [
    "#### Review The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ea3271d-def8-43c9-afc3-93a70fbc840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12321 (48.13 KB)\n",
      "Trainable params: 12321 (48.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad2ceab9-91ae-4e7a-b28f-1fa9d4a2a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 3223.4221 - mae: 3223.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3223.422119140625, 3223.422119140625]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.evaluate(normailized_feature_testing_data,label_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a1f0cf3-7d08-44a9-9043-a499e370bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Median: 9575.4421\n",
      "Training Label Mean: 13346.089736364485\n",
      "m3 MAE: 3223.422119140625 vs m2 MAE: 3163.11376953125\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Label Median: {label_training_data.median()}')\n",
    "print(f'Training Label Mean: {label_training_data.mean()}')\n",
    "print(f'm3 MAE: {m3.get_metrics_result()[\"mae\"].numpy()} vs m2 MAE: {m2.get_metrics_result()[\"mae\"].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac15f71-0610-4479-8542-8a0d1cf33200",
   "metadata": {},
   "source": [
    "Adding a layer made the mae roughly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375619d4-5345-4527-bf11-758e595a56be",
   "metadata": {},
   "source": [
    "### Change the Learning Rate less epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c494c0c-9144-4f39-8569-b7b1e9854d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 3s 6ms/step - loss: 3510.7605 - mae: 3510.7605\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.2773 - mae: 3485.2773\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3482.4819 - mae: 3482.4819\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3489.0757 - mae: 3489.0757\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.5991 - mae: 3488.5991\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3494.5928 - mae: 3494.5928\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.7686 - mae: 3487.7686\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.9607 - mae: 3485.9607\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3488.7549 - mae: 3488.7549\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3489.1785 - mae: 3489.1785\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3506.1489 - mae: 3506.1489\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.4146 - mae: 3484.4146\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3481.8342 - mae: 3481.8342\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3497.3767 - mae: 3497.3767\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.5110 - mae: 3485.5110\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3497.8796 - mae: 3497.8796\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3492.0408 - mae: 3492.0408\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.4338 - mae: 3484.4338\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.3669 - mae: 3498.3669\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.9248 - mae: 3485.9248\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3480.2039 - mae: 3480.2039\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.9619 - mae: 3488.9619\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.4609 - mae: 3496.4609\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3490.5063 - mae: 3490.5063\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3495.9028 - mae: 3495.9028\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.0950 - mae: 3487.0950\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.3955 - mae: 3487.3955\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3491.9612 - mae: 3491.9612\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3493.3364 - mae: 3493.3364\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3512.5054 - mae: 3512.5054\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3497.9985 - mae: 3497.9985\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.2434 - mae: 3502.2434\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3503.8032 - mae: 3503.8032\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3480.8286 - mae: 3480.8286\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3484.4680 - mae: 3484.4680\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3490.7930 - mae: 3490.7930\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3494.0649 - mae: 3494.0649\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3503.9114 - mae: 3503.9114\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3486.0576 - mae: 3486.0576\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3509.7026 - mae: 3509.7026\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3495.4399 - mae: 3495.4399\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3493.5073 - mae: 3493.5073\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3489.6760 - mae: 3489.6760\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.4531 - mae: 3488.4531\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3478.4622 - mae: 3478.4622\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.9863 - mae: 3489.9863\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3495.1831 - mae: 3495.1831\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.1218 - mae: 3487.1218\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3503.4702 - mae: 3503.4702\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3487.0396 - mae: 3487.0396\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3479.0144 - mae: 3479.0144\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3486.8059 - mae: 3486.8059\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3482.8071 - mae: 3482.8071\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3500.8154 - mae: 3500.8154\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3511.2195 - mae: 3511.2195\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.8831 - mae: 3485.8831\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.1084 - mae: 3488.1084\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3483.1650 - mae: 3483.1650\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3486.4912 - mae: 3486.4912\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3488.1587 - mae: 3488.1587\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3495.7007 - mae: 3495.7007\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3490.6890 - mae: 3490.6890\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.7341 - mae: 3484.7341\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.3640 - mae: 3489.3640\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3481.2261 - mae: 3481.2261\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3496.1794 - mae: 3496.1794\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3484.1841 - mae: 3484.1841\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.4292 - mae: 3485.4292\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3480.9167 - mae: 3480.9167\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.8347 - mae: 3489.8347\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.2981 - mae: 3487.2981\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3490.7551 - mae: 3490.7551\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3499.1602 - mae: 3499.1602\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.1614 - mae: 3491.1614\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3481.2334 - mae: 3481.2334\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3486.4187 - mae: 3486.4187\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3481.8494 - mae: 3481.8494\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3488.6729 - mae: 3488.6729\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.7092 - mae: 3487.7092\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3493.4900 - mae: 3493.4900\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.5762 - mae: 3491.5762\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3486.0894 - mae: 3486.0894\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.0815 - mae: 3488.0815\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3490.3613 - mae: 3490.3613\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3481.9177 - mae: 3481.9177\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3481.2058 - mae: 3481.2058\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.7839 - mae: 3488.7839\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.9512 - mae: 3487.9512\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3486.7156 - mae: 3486.7156\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3489.4817 - mae: 3489.4817\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.9375 - mae: 3485.9375\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3494.9062 - mae: 3494.9062\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.6230 - mae: 3487.6230\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.3987 - mae: 3485.3987\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3486.7446 - mae: 3486.7446\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.8154 - mae: 3487.8154\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3501.4971 - mae: 3501.4971\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3481.6580 - mae: 3481.6580\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3502.9363 - mae: 3502.9363\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3494.2498 - mae: 3494.2498\n"
     ]
    }
   ],
   "source": [
    "m4 = tf.keras.Sequential()\n",
    "\n",
    "# l4 = tf.keras.layers.Dense(100)\n",
    "\n",
    "m4.add(l1)\n",
    "# m4.add(l4)\n",
    "m4.add(l2)\n",
    "m4.add(l3)\n",
    "\n",
    "# Compile the model\n",
    "m4.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(learning_rate=.008),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model and save the history (we can plot this)\n",
    "# , verbose=0\n",
    "m4_history = m4.fit(normailized_feature_training_data, label_training_data, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cdb75-5387-4bdd-a242-70770cf18eb4",
   "metadata": {},
   "source": [
    "#### Review The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b4d9063-7b9a-410a-9cfe-3beea51e4b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12321 (48.13 KB)\n",
      "Trainable params: 12321 (48.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d266d57-5894-4100-9910-0c5c46dbed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 3223.4221 - mae: 3223.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3223.422119140625, 3223.422119140625]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4.evaluate(normailized_feature_testing_data,label_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4f68a6a-d516-49cd-b43e-bd7461df9ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Median: 9575.4421\n",
      "Training Label Mean: 13346.089736364485\n",
      "m3 MAE: 3494.249755859375 vs m2 MAE: 3163.11376953125\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Label Median: {label_training_data.median()}')\n",
    "print(f'Training Label Mean: {label_training_data.mean()}')\n",
    "print(f'm3 MAE: {m4.get_metrics_result()[\"mae\"].numpy()} vs m2 MAE: {m2.get_metrics_result()[\"mae\"].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefe319-0740-4fed-b05a-3662325b6791",
   "metadata": {},
   "source": [
    "setting the learning rate to `.008`, compared to the default `.001`, made the outcome slightly worse here :/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936aa0d-79dd-4abb-bdd5-4f521c4188e5",
   "metadata": {},
   "source": [
    "### Change the Learning Rate Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31d251ca-f58e-40e2-ae85-a29d011f864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 3s 6ms/step - loss: 3540.1484 - mae: 3540.1484\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3499.3572 - mae: 3499.3572\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.2312 - mae: 3488.2312\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3494.9104 - mae: 3494.9104\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.4202 - mae: 3491.4202\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3497.7678 - mae: 3497.7678\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3490.1836 - mae: 3490.1836\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.2910 - mae: 3487.2910\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3491.6929 - mae: 3491.6929\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3495.8262 - mae: 3495.8262\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3520.3125 - mae: 3520.3125\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.8164 - mae: 3487.8164\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3482.7441 - mae: 3482.7441\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3510.2600 - mae: 3510.2600\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.3149 - mae: 3491.3149\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.7566 - mae: 3498.7566\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.7661 - mae: 3498.7661\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.8101 - mae: 3487.8101\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.2498 - mae: 3509.2498\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.2043 - mae: 3489.2043\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3482.3862 - mae: 3482.3862\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3488.4395 - mae: 3488.4395\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3495.2896 - mae: 3495.2896\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3493.9971 - mae: 3493.9971\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3535.2964 - mae: 3535.2964\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3490.0095 - mae: 3490.0095\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.9321 - mae: 3488.9321\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.6750 - mae: 3502.6750\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3505.0737 - mae: 3505.0737\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3507.5300 - mae: 3507.5300\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3499.1841 - mae: 3499.1841\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3508.7507 - mae: 3508.7507\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3502.0920 - mae: 3502.0920\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.6548 - mae: 3485.6548\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3494.0027 - mae: 3494.0027\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3499.2178 - mae: 3499.2178\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3496.3865 - mae: 3496.3865\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3505.8816 - mae: 3505.8816\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3490.0427 - mae: 3490.0427\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3520.7771 - mae: 3520.7771\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3507.1648 - mae: 3507.1648\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.5571 - mae: 3498.5571\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3493.6125 - mae: 3493.6125\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3488.8826 - mae: 3488.8826\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3482.7305 - mae: 3482.7305\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.7993 - mae: 3491.7993\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.4912 - mae: 3492.4912\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3490.3088 - mae: 3490.3088\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3502.4829 - mae: 3502.4829\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3503.2703 - mae: 3503.2703\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.8735 - mae: 3484.8735\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3488.7502 - mae: 3488.7502\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.7288 - mae: 3487.7288\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3509.3267 - mae: 3509.3267\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3513.8994 - mae: 3513.8994\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.2119 - mae: 3491.2119\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3493.1650 - mae: 3493.1650\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.9812 - mae: 3487.9812\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.8193 - mae: 3491.8193\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3495.4663 - mae: 3495.4663\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3499.3489 - mae: 3499.3489\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3497.6179 - mae: 3497.6179\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3487.5103 - mae: 3487.5103\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.9077 - mae: 3492.9077\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.4131 - mae: 3485.4131\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.0811 - mae: 3496.0811\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3488.5515 - mae: 3488.5515\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3491.6892 - mae: 3491.6892\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.7234 - mae: 3484.7234\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.6514 - mae: 3489.6514\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3489.3477 - mae: 3489.3477\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3487.2004 - mae: 3487.2004\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3507.1978 - mae: 3507.1978\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3500.8391 - mae: 3500.8391\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3483.8801 - mae: 3483.8801\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3493.0049 - mae: 3493.0049\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.7744 - mae: 3485.7744\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3494.4929 - mae: 3494.4929\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.3030 - mae: 3492.3030\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3501.1536 - mae: 3501.1536\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.6230 - mae: 3496.6230\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3495.2131 - mae: 3495.2131\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3492.4189 - mae: 3492.4189\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3498.3599 - mae: 3498.3599\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3483.6519 - mae: 3483.6519\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.1389 - mae: 3484.1389\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3486.3140 - mae: 3486.3140\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.5459 - mae: 3485.5459\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3494.4602 - mae: 3494.4602\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3492.6377 - mae: 3492.6377\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3485.8967 - mae: 3485.8967\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.5437 - mae: 3496.5437\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.3047 - mae: 3491.3047\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3484.4326 - mae: 3484.4326\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3491.6902 - mae: 3491.6902\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3494.6145 - mae: 3494.6145\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3507.8342 - mae: 3507.8342\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3482.3210 - mae: 3482.3210\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3513.8071 - mae: 3513.8071\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3509.5012 - mae: 3509.5012\n"
     ]
    }
   ],
   "source": [
    "m5 = tf.keras.Sequential()\n",
    "\n",
    "# l4 = tf.keras.layers.Dense(100)\n",
    "\n",
    "m5.add(l1)\n",
    "# m5.add(l4)\n",
    "m5.add(l2)\n",
    "m5.add(l3)\n",
    "\n",
    "# Compile the model\n",
    "m5.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(learning_rate=.01),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model and save the history (we can plot this)\n",
    "# , verbose=0\n",
    "m5_history = m5.fit(normailized_feature_training_data, label_training_data, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98af83-443c-48b4-89ae-7e49a4007c99",
   "metadata": {},
   "source": [
    "#### Review The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "086a5a00-7ae7-494a-aff0-1bc284126b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2221 (8.68 KB)\n",
      "Trainable params: 2221 (8.68 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dbf8378-d5e9-472d-890f-c6e3f5264a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 3223.4221 - mae: 3223.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3223.422119140625, 3223.422119140625]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5.evaluate(normailized_feature_testing_data,label_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fd742bb-1981-499b-bbd8-b70da0842108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Median: 9575.4421\n",
      "Training Label Mean: 13346.089736364485\n",
      "m5 MAE: 3509.501220703125 vs m2 MAE: 3163.11376953125\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Label Median: {label_training_data.median()}')\n",
    "print(f'Training Label Mean: {label_training_data.mean()}')\n",
    "print(f'm5 MAE: {m5.get_metrics_result()[\"mae\"].numpy()} vs m2 MAE: {m2.get_metrics_result()[\"mae\"].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3c658-621f-4d0a-a9ce-9c81bed23696",
   "metadata": {},
   "source": [
    "setting the learning rate to `.01`, compared to the default `.001`, made the outcome slightly worse here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680c27e-92a5-4fe7-b00e-4c33e2b88b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
